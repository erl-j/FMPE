# -*- coding: utf-8 -*-
"""FMtest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F3E2gQnKbxuTVh701HsN_aRIrlLdBre-
"""
# %%
import os.path
import re
from scipy.io.wavfile import write
import scipy
from matplotlib import pyplot as plt
import os
from torch.utils.data import Dataset, DataLoader
from torch.utils import data
import time
import torch.optim as optim
import torch.nn.functional as F
from torch.autograd import Variable
import torch
import math
import numpy as np
import matplotlib.pyplot as plt
import random
import IPython.display as ipd
from SimpleFM import SimpleFM

SAMPLE_RATE = 44100
CLIP_DURATION = 1
N_SAMPLES = SAMPLE_RATE*CLIP_DURATION
MAX_RECURSION = 2
N_OPS = 5
N_PARAMS = 6


MODEL_PATH = "cnn.pt"


def plot(x):
    plt.figure(1)
    plt.plot(x)
    plt.show()


def play_audio(array, sample_rate):
    ipd.display(ipd.Audio(array, rate=sample_rate, autoplay=True))


CLIP_DURATION = 1
SAMPLE_RATE = 44100

fm = SimpleFM()


class DS(Dataset):
    def __getitem__(self, index):
        params = fm.generate_params()
        x = torch.as_tensor(fm.generate(params)).float()
        y = torch.as_tensor(params).float()
        return x, y

    def __len__(self):
        return 2048


trn_set = DS()

# %%


def get_trn_loader(batch_size):
    trn_loader = torch.utils.data.DataLoader(trn_set, num_workers=4, batch_size=batch_size,
                                             drop_last=True)
    return(trn_loader)


# %%


T = 44100

DROPOUT = 0.0


class SampleCNN(torch.torch.nn.Module):
    def __init__(self):
        super(SampleCNN, self).__init__()

        # 59049 x 1
        self.conv1 = torch.nn.Sequential(
            torch.nn.Conv1d(1, 128, kernel_size=3, stride=3, padding=0),
            torch.nn.BatchNorm1d(128),
            torch.nn.ReLU())
        # 19683 x 128
        self.conv2 = torch.nn.Sequential(
            torch.nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),
            torch.nn.BatchNorm1d(256),
            torch.nn.ReLU(),
            torch.nn.MaxPool1d(3, stride=3))
        # 6561 x 128
        self.conv3 = torch.nn.Sequential(
            torch.nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),
            torch.nn.BatchNorm1d(256),
            torch.nn.ReLU(),
            torch.nn.MaxPool1d(3, stride=3))
        # 2187 x 128
        self.conv4 = torch.nn.Sequential(
            torch.nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),
            torch.nn.BatchNorm1d(256),
            torch.nn.ReLU(),
            torch.nn.MaxPool1d(3, stride=3))
        # 729 x 256
        self.conv5 = torch.nn.Sequential(
            torch.nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),
            torch.nn.BatchNorm1d(256),
            torch.nn.ReLU(),
            torch.nn.MaxPool1d(3, stride=3))
        # 243 x 256
        self.conv6 = torch.nn.Sequential(
            torch.nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),
            torch.nn.BatchNorm1d(256),
            torch.nn.ReLU(),
            torch.nn.MaxPool1d(3, stride=3),
            torch.nn.Dropout(DROPOUT))
        # 81 x 256
        self.conv7 = torch.nn.Sequential(
            torch.nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),
            torch.nn.BatchNorm1d(256),
            torch.nn.ReLU(),
            torch.nn.MaxPool1d(3, stride=3))
        # 27 x 256
        self.conv8 = torch.nn.Sequential(
            torch.nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),
            torch.nn.BatchNorm1d(256),
            torch.nn.ReLU(),
            torch.nn.MaxPool1d(3, stride=3))

        self.conv9 = torch.nn.Sequential(
            torch.nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),
            torch.nn.BatchNorm1d(256),
            torch.nn.ReLU(),
            torch.nn.MaxPool1d(3, stride=3))

        # 1 x 512
        self.fc = torch.nn.Linear(512, 256)
        # add activation
        self.fc1 = torch.nn.Linear(256, 256)

        self.fc2 = torch.nn.Linear(256, N_PARAMS*N_OPS)

    def forward(self, x):
        # input x : 23 x 59049 x 1
        # expected conv1d input : minibatch_size x num_channel x width

        # print(x.shape)
        x = x.view(x.shape[0], 1, -1)
        # x : 23 x 1 x 59049

        out = self.conv1(x)
        # print(out.shape)
        out = self.conv2(out)
        # print(out.shape)
        out = self.conv3(out)
        # print(out.shape)
        out = self.conv4(out)
        # print(out.shape)
        out = self.conv5(out)
        # print(out.shape)
        out = self.conv6(out)
        # print(out.shape)
        out = self.conv7(out)
        # print(out.shape)
        out = self.conv8(out)
        # print(out.shape)
        out = self.conv9(out)

        out = out.view(x.shape[0], out.size(1) * out.size(2))
        out = self.fc(out)
        out = F.relu(out)
        out = self.fc1(out)
        out = F.relu(out)
        out = self.fc2(out)
        out = F.relu(out)

        return out


net = SampleCNN()


if os.path.isfile(MODEL_PATH):
    print("Found saved model, loading model state")
    net.load_state_dict(torch.load(MODEL_PATH))
else:

    print("No saved model found!")


if torch.cuda.is_available():
    net.cuda()
else:
    print("cuda not available")

# %%


def trainNet(net, batch_size, n_epochs, learning_rate):

    # Print all of the hyperparameters of the trning iteration:
    print("===== HYPERPARAMETERS =====")
    print("batch_size=", batch_size)
    print("epochs=", n_epochs)
    print("learning_rate=", learning_rate)
    print("=" * 30)

    # Get training data
    trn_loader = get_trn_loader(batch_size)
    n_batches = len(trn_loader)

    # Create our loss and optimizer functions
    loss, optimizer = createLossAndOptimizer(net, learning_rate)

    # Time for printing
    training_start_time = time.time()

    # Loop for n_epochs
    loss_progress = np.zeros((n_epochs, 1))
    attribute_progress = np.zeros((n_epochs, N_OPS*N_PARAMS))

    for epoch in range(n_epochs):

        running_loss = 0.0
        print_every = n_batches // 10
        start_time = time.time()
        total_train_loss = 0

        trn_delta = 0

        for i, data in enumerate(trn_loader, 0):
            # Get inputs
            inputs, labels = data

            # Wrap them in a Variable object
            inputs, labels = inputs.cuda(), labels.cuda()

            # Set the parameter gradients to zero
            optimizer.zero_grad()

            # Forward pass, backward pass, optimize
            outputs = net(inputs)

            loss_size = loss(outputs, labels)

            if type(trn_delta) == "Int":
                trn_delta = torch.abs(
                    trn_outputs - labels).cpu().detach().numpy()
            else:
                trn_delta = trn_delta + \
                    torch.abs(outputs - labels).cpu().detach().numpy()+trn_delta

            # computes gradients
            loss_size.backward()

            # performs update step
            optimizer.step()

            # Print statistics
            running_loss += loss_size.data.item()
            total_train_loss += loss_size.data.item()

            # Print every 10th batch of an epoch
            if (i + 1) % (print_every + 1) == 0:

                print("Epoch {}, {:d}% \t train_loss: {:.5f} took: {:.2f}s".format(
                    epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))
                # Reset running loss and time
                running_loss = 0.0
                start_time = time.time()

        per_attribute_delta_sum = np.sum(trn_delta, axis=0)

        attribute_progress[epoch, :] = per_attribute_delta_sum

        plt.plot(attribute_progress)
        fig_size = plt.gcf().get_size_inches()  # Get current size
        sizefactor = 1.5  # Set a zoom factor
        # Modify the current size by the factor
        plt.gcf().set_size_inches(sizefactor * fig_size)
        plt.show()

        loss_progress[epoch, :] = total_train_loss

        plt.plot(loss_progress)
        fig_size = plt.gcf().get_size_inches()  # Get current size
        sizefactor = 1.5  # Set a zoom factor
        # Modify the current size by the factor
        plt.gcf().set_size_inches(sizefactor * fig_size)
        plt.show()

        # print([val_outputs[0],labels[0]])

        try:
            play_audio(fm.generate(
                outputs[0].cpu().detach().numpy()), SAMPLE_RATE)
        except:
            print("failed producing clip")

        time.sleep(2)

        play_audio(fm.generate(labels[0].cpu().detach().numpy()), SAMPLE_RATE)

        ipd.set_matplotlib_close(close=True)

        print("saving model")
        torch.save(net.state_dict(), MODEL_PATH)

    print("Training finished, took {:.2f}s".format(
        time.time() - training_start_time))


def createLossAndOptimizer(net, learning_rate):
    # Loss function
    loss = torch.nn.MSELoss()
    # Optimizer
    optimizer = optim.Adam(net.parameters(), lr=learning_rate)
    return(loss, optimizer)


# %%
trainNet(net, batch_size=32, n_epochs=1000, learning_rate=0.001)
# %%
